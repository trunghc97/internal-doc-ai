"""
Service cho ph√°t hi·ªán th√¥ng tin nh·∫°y c·∫£m
"""

import re
from typing import List, Dict, Any
import pdfplumber
from docx import Document
from fastapi import HTTPException

class SensitiveCategory:
    NO_CATEGORY = "Kh√¥ng ph√¢n lo·∫°i"
    INTERNAL = "D·ªØ li·ªáu n·ªôi b·ªô nh·∫°y c·∫£m"
    IDENTIFIABLE = "D·ªØ li·ªáu ƒë·ªãnh danh nh·∫°y c·∫£m"

class SubType:
    # ƒê·ªãnh danh c√° nh√¢n
    PHONE = "S·ªë ƒëi·ªán tho·∫°i"
    ID_CARD = "S·ªë ch·ª©ng minh nh√¢n d√¢n"
    PERSONAL_ID = "S·ªë ƒë·ªãnh danh c√° nh√¢n"
    PASSPORT = "S·ªë h·ªô chi·∫øu"
    LICENSE = "S·ªë gi·∫•y ph√©p l√°i xe"
    PLATE = "S·ªë bi·ªÉn s·ªë xe"
    TAX_ID_PERSONAL = "S·ªë m√£ s·ªë thu·∫ø c√° nh√¢n"
    SOCIAL_INSURANCE = "S·ªë b·∫£o hi·ªÉm x√£ h·ªôi"
    HEALTH_INSURANCE = "S·ªë th·∫ª b·∫£o hi·ªÉm y t·∫ø"
    # ƒê·ªãnh danh t·ªï ch·ª©c
    TAX_ID_ORG = "M√£ s·ªë thu·∫ø t·ªï ch·ª©c"
    # N·ªôi b·ªô
    BANK_ACCOUNT = "S·ªë t√†i kho·∫£n ng√¢n h√†ng"
    SALARY = "Th√¥ng tin l∆∞∆°ng th∆∞·ªüng"
    CARD_NUMBER = "S·ªë th·∫ª"
    SECRET_KEY = "Secret/API Key/Token"
    PASSWORD = "M·∫≠t kh·∫©u"
    UNKNOWN = "Kh√¥ng x√°c ƒë·ªãnh"

SUBTYPE_DETECT_RULES = [
    # ƒê·ªãnh danh c√° nh√¢n (IDENTIFIABLE)
    {
        "subtype": SubType.PHONE,
        "category": SensitiveCategory.IDENTIFIABLE,
        "keywords": [
            "ƒëi·ªán tho·∫°i", "dien thoai", "ƒët", "dt", "sdt", "s·ªë dt", "so dt", "phone", "tel", "telephone", 
            "mobile", "mobifone", "li√™n h·ªá", "lien he", "li√™n l·∫°c", "lien lac", "hotline", "contact number"
        ],
        "regex": r"(?:\+?84[\s\-\.]?)?0?(3[2-9]|5[689]|7[06-9]|8[1-689]|9[0-46-9])([\s\-\.]?\d){7,8}\b"
    },
    {
        "subtype": SubType.ID_CARD,
        "category": SensitiveCategory.IDENTIFIABLE,
        "keywords": [
            "ch·ª©ng minh nh√¢n d√¢n", "chung minh nhan dan", "cmnd", "id card", "cmt", "cmnd/cccd", 
            "gi·∫•y cmnd", "giay cmnd", "s·ªë cmnd", "so cmnd", "identity card"
        ],
        "regex": r"\b(\d[\s\-\.]?){9}\b"
    },
    {
        "subtype": SubType.PERSONAL_ID,
        "category": SensitiveCategory.IDENTIFIABLE,
        "keywords": [
            "cƒÉn c∆∞·ªõc c√¥ng d√¢n", "can cuoc cong dan", "cccd", "cccd/cc", "id ca nhan", 
            "personal id", "citizen id", "m√£ ƒë·ªãnh danh", "ma dinh danh", "cƒÉn c∆∞·ªõc", "can cuoc", 
            "s·ªë cccd", "so cccd", "gi·∫•y cccd", "giay cccd"
        ],
        "regex": r"\b(\d[\s\-\.]?){12}\b"
    },
    {
        "subtype": SubType.PASSPORT,
        "category": SensitiveCategory.IDENTIFIABLE,
        "keywords": [
            "h·ªô chi·∫øu", "ho chieu", "passport", "pp", "passport number", "so ho chieu", "s·ªë h·ªô chi·∫øu", 
            "gi·∫•y h·ªô chi·∫øu", "giay ho chieu"
        ],
        "regex": r"\b([A-Z]{1,2}[\s\-\.]?(\d[\s\-\.]?){7})\b"
    },
    {
        "subtype": SubType.LICENSE,
        "category": SensitiveCategory.IDENTIFIABLE,
        "keywords": [
            "gi·∫•y ph√©p l√°i xe", "giay phep lai xe", "gplx", "driver license", "driving license", "b·∫±ng l√°i xe", 
            "bang lai xe", "bang lai", "s·ªë gplx", "so gplx", "b·∫±ng l√°i", "gi·∫•y l√°i xe", "giay lai xe"
        ],
        "regex": r"\b(\d[\s\-\.]?){12}\b"
    },
    {
        "subtype": SubType.PLATE,
        "category": SensitiveCategory.IDENTIFIABLE,
        "keywords": [
            "bi·ªÉn s·ªë xe", "bien so xe", "bienso", "license plate", "plate number", "bks", 
            "bi·ªÉn ki·ªÉm so√°t", "bien kiem soat", "s·ªë xe", "so xe", "bi·ªÉn s·ªë", "bien so"
        ],
        "regex": r"\b\d{2}[A-Z]{1,2}[\s\-\.]?\d{4,5}\b"
    },
    {
        "subtype": SubType.TAX_ID_PERSONAL,
        "category": SensitiveCategory.IDENTIFIABLE,
        "keywords": [
            "m√£ s·ªë thu·∫ø c√° nh√¢n", "ma so thue ca nhan", "mst c√° nh√¢n", "mst ca nhan", "tax id", 
            "tax code", "m√£ s·ªë thu·∫ø", "ma so thue", "mst", "s·ªë mst", "so mst", "s·ªë thu·∫ø", "so thue"
        ],
        "regex": r"\b(\d[\s\-\.]?){10}(([\s\-\.]?\d){3})?\b"
    },
    {
        "subtype": SubType.SOCIAL_INSURANCE,
        "category": SensitiveCategory.IDENTIFIABLE,
        "keywords": [
            "b·∫£o hi·ªÉm x√£ h·ªôi", "bao hiem xa hoi", "bhxh", "social insurance", "s·ªë bhxh", "so bhxh", 
            "m√£ bhxh", "ma bhxh"
        ],
        "regex": r"\b(\d[\s\-\.]?){10}\b"
    },
    {
        "subtype": SubType.HEALTH_INSURANCE,
        "category": SensitiveCategory.IDENTIFIABLE,
        "keywords": [
            "b·∫£o hi·ªÉm y t·∫ø", "bao hiem y te", "bhyt", "health insurance", "th·∫ª bhyt", "the bhyt", 
            "s·ªë th·∫ª b·∫£o hi·ªÉm", "so the bao hiem", "s·ªë bhyt", "so bhyt", "m√£ bhyt", "ma bhyt"
        ],
        "regex": r"\b[A-Z]{2}([\s\-\.]?\d){13}\b"
    },
    # ƒê·ªãnh danh t·ªï ch·ª©c (IDENTIFIABLE)
    {
        "subtype": SubType.TAX_ID_ORG,
        "category": SensitiveCategory.IDENTIFIABLE,
        "keywords": [
            "m√£ s·ªë thu·∫ø", "ma so thue", "mst t·ªï ch·ª©c", "mst to chuc", "tax id org", "tax code org", 
            "m√£ s·ªë thu·∫ø doanh nghi·ªáp", "ma so thue doanh nghiep", "m√£ s·ªë thu·∫ø cty", "ma so thue cty"
        ],
        "regex": r"\b\d{10}-\d{3}\b"
    },
    # N·ªôi b·ªô nh·∫°y c·∫£m (INTERNAL)
    {
        "subtype": SubType.BANK_ACCOUNT,
        "category": SensitiveCategory.INTERNAL,
        "keywords": [
            "s·ªë t√†i kho·∫£n", "so tai khoan", "stk", "bank account", "t√†i kho·∫£n ng√¢n h√†ng", "tai khoan ngan hang", 
            "account number", "s·ªë tk", "so tk", "tk ng√¢n h√†ng", "tk ngan hang", "s·ªë t√†i kho·∫£n ng√¢n h√†ng", "so tai khoan ngan hang"
        ],
        "regex": r"\b(\d[\s\-\.]?){8,16}\b"
    },
    {
        "subtype": SubType.CARD_NUMBER,
        "category": SensitiveCategory.INTERNAL,
        "keywords": [
            "s·ªë th·∫ª", "so the", "card number", "credit card", "debit card", "s·ªë th·∫ª t√≠n d·ª•ng", 
            "so the tin dung", "s·ªë th·∫ª ng√¢n h√†ng", "so the ngan hang", "card", "th·∫ª ng√¢n h√†ng", "the ngan hang"
        ],
        "regex": r"\b(\d[\s\-\.]?){16}\b"
    },
     {
         "subtype": SubType.SALARY,
         "category": SensitiveCategory.INTERNAL,
         "keywords": [
             "l∆∞∆°ng", "luong", "b·∫£ng l∆∞∆°ng", "bang luong", "salary", "th∆∞·ªüng", "thuong", "bonus", 
             "th√¥ng tin l∆∞∆°ng th∆∞·ªüng", "thong tin luong thuong", "phi·∫øu l∆∞∆°ng", "phieu luong", "b·∫£ng th∆∞·ªüng", "bang thuong", "b·∫£ng l∆∞∆°ng th∆∞·ªüng", "bang luong thuong", "quy·∫øt to√°n l∆∞∆°ng", "quyet toan luong", "salary slip", "salary report"
         ],
         "regex": ""  # Kh√¥ng c√≥ regex, l·∫•y value m·∫∑c ƒë·ªãnh
     },
     {
         "subtype": SubType.SECRET_KEY,
         "category": SensitiveCategory.INTERNAL,
         "keywords": [
             "secret key", "api key", "access token", "session token", "token", "client secret", "private key", 
             "api_token", "api-key", "client_secret", "client-key", "consumer key", "jwt", "oauth token", "oauth", "authorization code", "refresh token"
         ],
         "regex": ""  # Kh√¥ng c√≥ regex, l·∫•y value m·∫∑c ƒë·ªãnh
     },
     {
         "subtype": SubType.PASSWORD,
         "category": SensitiveCategory.INTERNAL,
         "keywords": [
             "m·∫≠t kh·∫©u", "mat khau", "password", "pass", "pwd", "m√£ kh√≥a b√≠ m·∫≠t", "ma khoa bi mat", 
             "login password", "user password", "admin password", "admin pass", "root password", "passcode"
         ],
         "regex": ""  # Kh√¥ng c√≥ regex, l·∫•y value m·∫∑c ƒë·ªãnh
     },
]

class DetectionService:
    """Service cho ph√°t hi·ªán th√¥ng tin nh·∫°y c·∫£m"""
    
    def __init__(self):
        self.rules = SUBTYPE_DETECT_RULES
    
    def extract_text_from_pdf(self, file_path: str) -> str:
        """Extract text from PDF file using pdfplumber"""
        text = ""
        try:
            with pdfplumber.open(file_path) as pdf:
                for page in pdf.pages:
                    text += page.extract_text() or ""
            return text
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Error extracting text from PDF: {str(e)}")

    def extract_text_from_docx(self, file_path: str) -> str:
        """Extract text from DOCX file using python-docx"""
        try:
            doc = Document(file_path)
            return "\n".join([paragraph.text for paragraph in doc.paragraphs])
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Error extracting text from DOCX: {str(e)}")
    
    def detect_sensitive_by_rules(self, text: str) -> List[Dict[str, Any]]:
        """
        Detect sensitive information using SUBTYPE_DETECT_RULES
        ∆Øu ti√™n keyword, l·∫•y gi√° tr·ªã ngay sau keyword l√†m value
        """
        matches = []
        text_lower = text.lower()
        
        for rule in self.rules:
            subtype = rule["subtype"]
            category = rule["category"]
            keywords = rule["keywords"]
            regex_pattern = rule["regex"]
            
            # Detect by keywords - ∆∞u ti√™n v√† l·∫•y value sau keyword
            keyword_matches = []
            for keyword in keywords:
                keyword_lower = keyword.lower()
                start_pos = 0
                while True:
                    pos = text_lower.find(keyword_lower, start_pos)
                    if pos == -1:
                        break
                    
                    # T√¨m gi√° tr·ªã ngay sau keyword
                    keyword_end = pos + len(keyword)
                    value_after_keyword = self._extract_value_after_keyword(text, keyword_end, subtype)
                    
                    if value_after_keyword:
                        # Ki·ªÉm tra xem rule c√≥ regex kh√¥ng
                        if regex_pattern and regex_pattern.strip():
                            # C√≥ regex: value ph·∫£i match regex m·ªõi ƒë∆∞·ª£c ch·∫•p nh·∫≠n
                            refined_value = self._apply_regex_to_value(value_after_keyword["value"], regex_pattern)
                            
                            if refined_value:
                                # Ch·ªâ th√™m khi regex match th√†nh c√¥ng
                                keyword_matches.append({
                                    "category": category,
                                    "subtype": subtype,
                                    "value": refined_value,
                                    "start": pos,
                                    "end": value_after_keyword["end"],
                                    "method": "keyword+regex",
                                    "keyword_found": keyword
                                })
                            # N·∫øu regex kh√¥ng match th√¨ b·ªè qua, kh√¥ng th√™m v√†o k·∫øt qu·∫£
                        else:
                            # Kh√¥ng c√≥ regex: l·∫•y value m·∫∑c ƒë·ªãnh sau keyword
                            keyword_matches.append({
                                "category": category,
                                "subtype": subtype,
                                "value": value_after_keyword["value"],
                                "start": pos,
                                "end": value_after_keyword["end"],
                                "method": "keyword",
                                "keyword_found": keyword
                            })
                    else:
                        # N·∫øu kh√¥ng t√¨m th·∫•y value sau keyword, l·∫•y keyword l√†m value
                        keyword_matches.append({
                            "category": category,
                            "subtype": subtype,
                            "value": text[pos:pos+len(keyword)],
                            "start": pos,
                            "end": pos + len(keyword),
                            "method": "keyword",
                            "keyword_found": keyword
                        })
                    
                    start_pos = pos + 1
            
            # Ch·ªâ th√™m keyword matches - b·∫Øt bu·ªôc ph·∫£i match keyword tr∆∞·ªõc
            matches.extend(keyword_matches)
        
        return matches
    
    def _extract_value_after_keyword(self, text: str, keyword_end: int, subtype: str) -> Dict[str, Any]:
        """
        Tr√≠ch xu·∫•t gi√° tr·ªã ngay sau keyword
        """
        # B·ªè qua kho·∫£ng tr·∫Øng v√† d·∫•u ph√¢n c√°ch
        separators = [" ", ":", "=", "-", "\t", "\n"]
        start_pos = keyword_end
        
        # B·ªè qua c√°c k√Ω t·ª± ph√¢n c√°ch
        while start_pos < len(text) and text[start_pos] in separators:
            start_pos += 1
        
        if start_pos >= len(text):
            return None
        
        # L·∫•y ƒëo·∫°n text d√†i h∆°n ƒë·ªÉ c√≥ th·ªÉ ch·ª©a s·ªë c√≥ d·∫•u c√°ch
        # L·∫•y t·ªëi ƒëa 100 k√Ω t·ª± sau keyword ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ ƒë·ªß d·ªØ li·ªáu
        max_length = min(100, len(text) - start_pos)
        pattern = r"[\w\d\s\-\.]{1," + str(max_length) + "}"
        
        # T√¨m value t·ª´ v·ªã tr√≠ start_pos
        remaining_text = text[start_pos:]
        match = re.match(pattern, remaining_text)
        
        if match:
            value = match.group().strip()
            # Lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng mong mu·ªën ·ªü cu·ªëi
            value = re.sub(r'[^\w\d\s\-\.]$', '', value).strip()
            
            if value and len(value) > 0:
                return {
                    "value": value,
                    "start": start_pos,
                    "end": start_pos + len(value)
                }
        
        # Fallback: l·∫•y t·ª´ ti·∫øp theo
        words = remaining_text.split()
        if words:
            first_word = words[0]
            # Lo·∫°i b·ªè d·∫•u c√¢u ·ªü cu·ªëi
            first_word = re.sub(r'[^\w\d\-\.]', '', first_word)
            if first_word:
                return {
                    "value": first_word,
                    "start": start_pos,
                    "end": start_pos + len(first_word)
                }
        
        return None
    
    def _apply_regex_to_value(self, value: str, regex_pattern: str) -> str:
        """
        √Åp d·ª•ng regex l√™n value ƒë·ªÉ l√†m s·∫°ch v√† chu·∫©n h√≥a
        """
        try:
            # T√¨m regex match trong value
            match = re.search(regex_pattern, value)
            if match:
                # Tr·∫£ v·ªÅ ph·∫ßn match v√† lo·∫°i b·ªè d·∫•u c√°ch th·ª´a
                matched_value = match.group()
                # Chu·∫©n h√≥a: lo·∫°i b·ªè d·∫•u c√°ch th·ª´a nh∆∞ng gi·ªØ l·∫°i c·∫•u tr√∫c
                return re.sub(r'\s+', ' ', matched_value).strip()
            return None
        except re.error:
            return None
    
    def process_file(self, file_path: str, mime_type: str) -> str:
        """Process file v√† extract text d·ª±a tr√™n mime type"""
        if mime_type == "application/pdf":
            return self.extract_text_from_pdf(file_path)
        elif mime_type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            return self.extract_text_from_docx(file_path)
        else:
            raise HTTPException(status_code=400, detail="Unsupported file type")
    
    def analyze_document(self, file_path: str, filename: str, mime_type: str, file_size: int) -> Dict[str, Any]:
        """Ph√¢n t√≠ch document ho√†n ch·ªânh"""
        
        # Extract text
        content_text = self.process_file(file_path, mime_type)
        
        # Detect sensitive information
        matches = self.detect_sensitive_by_rules(content_text)
        
        # Log results
        self._log_detection_results(filename, mime_type, content_text, matches, file_size)
        
        return {
            "success": True,
            "filename": filename,
            "mime_type": mime_type,
            "file_size": file_size,
            "content_length": len(content_text),
            "total_matches": len(matches),
            "matches": matches,
            "categories_found": list(set([match["category"] for match in matches])),
            "subtypes_found": list(set([match["subtype"] for match in matches]))
        }
    
    def _log_detection_results(self, filename: str, mime_type: str, content_text: str, matches: List[Dict], file_size: int):
        """Log k·∫øt qu·∫£ detection"""
        
        result_data = {
            "filename": filename,
            "mime_type": mime_type,
            "content_text": content_text[:500] + "..." if len(content_text) > 500 else content_text,
            "matches": matches,
            "file_size": file_size,
            "uploaded_by": "api_user"
        }
        
        print("=" * 80)
        print("üîç SENSITIVE DATA DETECTION RESULT")
        print("=" * 80)
        print(f"üìÅ Filename: {result_data['filename']}")
        print(f"üìÑ MIME Type: {result_data['mime_type']}")
        print(f"üìä File Size: {result_data['file_size']} bytes")
        print(f"üë§ Uploaded By: {result_data['uploaded_by']}")
        print(f"üìù Content Length: {len(content_text)} characters")
        print(f"üéØ Total Matches: {len(matches)}")
        print()
        
        if matches:
            print("üîé DETECTED SENSITIVE DATA:")
            
            # T√°ch text th√†nh c√°c d√≤ng ƒë·ªÉ t√¨m line number
            lines = content_text.split('\n')
            
            for i, match in enumerate(matches, 1):
                # T√¨m line number v√† column c·ªßa match
                line_num, col_num, line_content = self._find_line_and_column(content_text, match['start'])
                
                print(f"  {i}. Category: {match['category']}")
                print(f"     SubType: {match['subtype']}")
                print(f"     Value: {match['value']}")
                print(f"     Position: {match['start']}-{match['end']} (Line {line_num}, Col {col_num})")
                print(f"     Method: {match['method']}")
                if 'keyword_found' in match:
                    print(f"     Keyword Found: {match['keyword_found']}")
                print(f"     Line Content: {line_content.strip()}")
                print()
        else:
            print("‚úÖ No sensitive data detected")
        
        print("=" * 80)
    
    def _find_line_and_column(self, text: str, position: int) -> tuple:
        """
        T√¨m line number v√† column number c·ªßa position trong text
        Returns: (line_number, column_number, line_content)
        """
        lines = text.split('\n')
        current_pos = 0
        
        for line_num, line in enumerate(lines, 1):
            line_length = len(line) + 1  # +1 cho k√Ω t·ª± newline
            
            if current_pos + line_length > position:
                # Position n·∫±m trong d√≤ng n√†y
                column = position - current_pos + 1
                return line_num, column, line
            
            current_pos += line_length
        
        # N·∫øu kh√¥ng t√¨m th·∫•y (tr∆∞·ªùng h·ª£p edge case)
        return len(lines), 1, lines[-1] if lines else ""

# Kh·ªüi t·∫°o service instance
detection_service = DetectionService()
