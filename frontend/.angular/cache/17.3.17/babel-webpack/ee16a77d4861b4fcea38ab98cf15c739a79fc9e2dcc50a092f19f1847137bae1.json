{"ast":null,"code":"import { throwError } from 'rxjs';\nimport { catchError } from 'rxjs/operators';\nimport * as i0 from \"@angular/core\";\nimport * as i1 from \"@angular/common/http\";\nexport let LlmService = /*#__PURE__*/(() => {\n  var _LlmService;\n  class LlmService {\n    constructor(http) {\n      this.http = http;\n      this.llmBaseUrl = 'http://localhost:8082';\n    }\n    chat(messages) {\n      const request = {\n        messages\n      };\n      return this.http.post(`${this.llmBaseUrl}/chat`, request).pipe(catchError(this.handleError));\n    }\n    handleError(error) {\n      console.error('LLM API error:', error);\n      return throwError(() => error);\n    }\n  }\n  _LlmService = LlmService;\n  _LlmService.ɵfac = function LlmService_Factory(t) {\n    return new (t || _LlmService)(i0.ɵɵinject(i1.HttpClient));\n  };\n  _LlmService.ɵprov = /*@__PURE__*/i0.ɵɵdefineInjectable({\n    token: _LlmService,\n    factory: _LlmService.ɵfac,\n    providedIn: 'root'\n  });\n  return LlmService;\n})();","map":{"version":3,"names":["throwError","catchError","LlmService","_LlmService","constructor","http","llmBaseUrl","chat","messages","request","post","pipe","handleError","error","console","i0","ɵɵinject","i1","HttpClient","factory","ɵfac","providedIn"],"sources":["/Users/huy/Documents/internal-doc-ai/frontend/src/app/services/llm.service.ts"],"sourcesContent":["import { Injectable } from '@angular/core';\nimport { HttpClient, HttpErrorResponse } from '@angular/common/http';\nimport { Observable, throwError } from 'rxjs';\nimport { catchError } from 'rxjs/operators';\n\nexport interface ChatMessage {\n  role: string;\n  content: string;\n}\n\nexport interface ChatRequest {\n  messages: ChatMessage[];\n}\n\nexport interface ChatResponse {\n  answer: string;\n}\n\n@Injectable({\n  providedIn: 'root'\n})\nexport class LlmService {\n  private llmBaseUrl = 'http://localhost:8082';\n\n  constructor(private http: HttpClient) {}\n\n  chat(messages: ChatMessage[]): Observable<ChatResponse> {\n    const request: ChatRequest = { messages };\n    return this.http.post<ChatResponse>(`${this.llmBaseUrl}/chat`, request)\n      .pipe(\n        catchError(this.handleError)\n      );\n  }\n\n  private handleError(error: HttpErrorResponse): Observable<never> {\n    console.error('LLM API error:', error);\n    return throwError(() => error);\n  }\n}\n"],"mappings":"AAEA,SAAqBA,UAAU,QAAQ,MAAM;AAC7C,SAASC,UAAU,QAAQ,gBAAgB;;;AAkB3C,WAAaC,UAAU;EAAA,IAAAC,WAAA;EAAjB,MAAOD,UAAU;IAGrBE,YAAoBC,IAAgB;MAAhB,KAAAA,IAAI,GAAJA,IAAI;MAFhB,KAAAC,UAAU,GAAG,uBAAuB;IAEL;IAEvCC,IAAIA,CAACC,QAAuB;MAC1B,MAAMC,OAAO,GAAgB;QAAED;MAAQ,CAAE;MACzC,OAAO,IAAI,CAACH,IAAI,CAACK,IAAI,CAAe,GAAG,IAAI,CAACJ,UAAU,OAAO,EAAEG,OAAO,CAAC,CACpEE,IAAI,CACHV,UAAU,CAAC,IAAI,CAACW,WAAW,CAAC,CAC7B;IACL;IAEQA,WAAWA,CAACC,KAAwB;MAC1CC,OAAO,CAACD,KAAK,CAAC,gBAAgB,EAAEA,KAAK,CAAC;MACtC,OAAOb,UAAU,CAAC,MAAMa,KAAK,CAAC;IAChC;;gBAhBWX,UAAU;;qBAAVA,WAAU,EAAAa,EAAA,CAAAC,QAAA,CAAAC,EAAA,CAAAC,UAAA;EAAA;;WAAVhB,WAAU;IAAAiB,OAAA,EAAVjB,WAAU,CAAAkB,IAAA;IAAAC,UAAA,EAFT;EAAM;EAAA,OAEPnB,UAAU;AAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}